{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from pandas.errors import EmptyDataError\n",
    "from skimpy import skim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOE and NREL Laws and Incentives Data #\n",
    "csv_url = \"https://developer.nrel.gov/api/transportation-incentives-laws/v1.csv?api_key=GAmcMbhWclW5qULHxvWQWtUw52EsehwTPtfu4cz8&expired=false&incentive_type=GNT%2CTAX%2CLOANS%2CRBATE%2CEXEM%2CTOU%2COTHER&law_type=INC%2CPROG%2CLAWREG%2CSTATEINC&regulation_type=REQ%2CDREST%2CREGIS%2CEVFEE%2CFUEL%2CSTD%2CRFS%2CAIRQEMISSIONS%2CCCEINIT%2CUTILITY%2CBUILD%2CRTC%2COTHER&technology=BIOD%2CETH%2CNG%2CLPG%2CHY%2CELEC%2CPHEV%2CHEV%2CNEVS%2CRD%2CAFTMKTCONV%2CEFFEC%2CIR%2CAUTONOMOUS%2COTHER&user_type=FLEET%2CGOV%2CTRIBAL%2CIND%2CSTATION%2CAFP%2CPURCH%2CMAN%2CMUD%2CTRANS%2COTHER\"\n",
    "\n",
    "# Load the CSV directly into a DataFrame\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n",
    "\n",
    "## limits:\n",
    "# some fields are long text or JSON-like strings \n",
    "\n",
    "# save the csv file \n",
    "response = requests.get(csv_url)\n",
    "with open(\"nrel_laws_incentives.csv\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"CSV file downloaded successfully.\")\n",
    "f.close()\n",
    "\n",
    "nrel_laws_incentives = pd.read_csv(\"nrel_laws_incentives.csv\")\n",
    "print(nrel_laws_incentives.head())\n",
    "skim(nrel_laws_incentives)\n",
    "\n",
    "## initial data checks:\n",
    "# need to drop any potential redundant variables\n",
    "# missingness is present in a lot of the variables, with some having NA percentages close to 100%, thus need to look more deeply if these variables are importance overall \n",
    "# there are a lot of string variables, which prepares will be hard to parse through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open EI Data Scraping #\n",
    "# List of U.S. states (you can add more or switch to cities)\n",
    "states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \n",
    "    \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n",
    "    \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \n",
    "    \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "# Could also look at specific cities if wanted to via this program\n",
    "\n",
    "# Store all results here\n",
    "all_incentives = []\n",
    "\n",
    "# Loop through each state and query the API\n",
    "for state in states:\n",
    "    print(f\"Fetching: {state}\")\n",
    "    url = f\"https://openei.org/services/api/place/{state}/incentives/v1\"\n",
    "    params = {\n",
    "        \"format\": \"json\",\n",
    "        \"active\": \"yes\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        results = data.get(\"results\", {}).get(\"bindings\", [])\n",
    "\n",
    "        for item in results:\n",
    "            all_incentives.append({\n",
    "                \"location\": state,\n",
    "                \"name\": item[\"incentive_name\"][\"value\"],\n",
    "                \"type\": item[\"incentive_type\"][\"value\"],\n",
    "                \"description\": item[\"incentive_descr\"][\"value\"],\n",
    "                \"link\": item[\"incentive_page\"][\"value\"]\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {state}: {e}\")\n",
    "\n",
    "    time.sleep(1)  # Add delay to avoid overwhelming server\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_incentives)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"all_state_incentives.csv\", index=False)\n",
    "print(\"Done! Saved all incentives.\")\n",
    "\n",
    "all_state_incentives = pd.read_csv(\"all_state_incentives.csv\")\n",
    "print(all_state_incentives.head())\n",
    "skim(all_state_incentives)\n",
    "\n",
    "# limitations \n",
    "## there is a lot of text making it hard to parse through this \n",
    "## data takes a while to load since it is scraping through a lot of data and information \n",
    "\n",
    "# initial check\n",
    "## all of the data presented is string data, so need to look further to see if this would actually be helpful information within it\n",
    "## no NA data found though "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 48C Energy Communities Data #\n",
    "url = \"http://edx.netl.doe.gov/dataset/22944d5d-d063-4890-a995-064bc59b5a78/resource/3d01f2d6-1c1c-498d-8db2-3a51aa3c07f2/download\"\n",
    "\n",
    "# Spoof headers to mimic a browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": \"http://edx.netl.doe.gov/\",\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Unzip and preview\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "    print(\"Files in ZIP:\", z.namelist())\n",
    "    for file in z.namelist():\n",
    "        if file.endswith(\".csv\"):\n",
    "            with z.open(file) as f:\n",
    "                df = pd.read_csv(f)\n",
    "                print(f\"\\nPreview of {file}:\")\n",
    "                print(df.head())\n",
    "                skim(df)\n",
    "\n",
    "                filename = os.path.basename(file)  # handles nested folders inside zip\n",
    "                df.to_csv(filename, index=False)\n",
    "                print(f\"Saved {filename}\")\n",
    "\n",
    "\n",
    "\n",
    " # initial check \n",
    " # missingness is only present in one variable, there is a lot of missingness so need to see if it is valuable information to our mission \n",
    " # good mix of numerical and string variables \n",
    "\n",
    "data_48c = pd.read_csv(\"48C_CensusTractDesignation.csv\")\n",
    "print(data_48c.head())\n",
    "skim(data_48c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
