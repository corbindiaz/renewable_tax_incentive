{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c03dc6-3f93-45d4-9d5d-ce69a69cdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import zipfile\n",
    "import openpyxl\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "\n",
    "# ========================\n",
    "# Download RECS Data Files\n",
    "# ========================\n",
    "def download_recs_files():\n",
    "    base_url_for_year = 'https://www.eia.gov/consumption/residential/data/'\n",
    "    response = requests.get(base_url_for_year)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find available RECS years\n",
    "    year_links = soup.find_all('a', href=re.compile(r'^/consumption/residential/data/\\d{4}/$'))\n",
    "    years = [int(re.search(r'\\d{4}', link['href']).group()) for link in year_links]\n",
    "    if not years:\n",
    "        print(\"‚ùå No RECS years found.\")\n",
    "        return\n",
    "\n",
    "    year = max(years)\n",
    "    base_path = os.path.join('STAT 390 Project', 'Energy Data', 'RECS', str(year))\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"üìÇ Saving to {base_path}\")\n",
    "\n",
    "    # Navigate to RECS microdata page\n",
    "    base_url = f'https://www.eia.gov/consumption/residential/data/{year}/'\n",
    "    microdata_url = f'{base_url}index.php?view=microdata'\n",
    "    soup = BeautifulSoup(requests.get(microdata_url).text, 'html.parser')\n",
    "\n",
    "    links = soup.find_all('a', href=True)\n",
    "    zip_file = csv_file = codebook_file = None\n",
    "\n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        text = link.get_text(strip=True).lower()\n",
    "        if 'zip' in text and href.endswith('.zip'):\n",
    "            zip_file = href\n",
    "        elif 'csv' in text and href.endswith('.csv'):\n",
    "            csv_file = href\n",
    "        elif ('xlsx' in text or 'codebook' in href.lower()) and href.endswith('.xlsx'):\n",
    "            codebook_file = href\n",
    "\n",
    "    if zip_file:\n",
    "        # Download and extract zip file\n",
    "        full_zip_url = f'{base_url}{zip_file}'\n",
    "        response = requests.get(full_zip_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if 'application/zip' not in response.headers.get('Content-Type', ''):\n",
    "            print(\"‚ùå Downloaded file is not a ZIP archive.\")\n",
    "            return\n",
    "\n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "            for file_name in z.namelist():\n",
    "                if file_name.endswith('.csv') or file_name.endswith('.txt'):\n",
    "                    extracted_path = os.path.join(base_path, os.path.basename(file_name))\n",
    "                    with open(extracted_path, 'wb') as f:\n",
    "                        f.write(z.read(file_name))\n",
    "                    print(f\"‚úÖ Downloaded {file_name}\")\n",
    "        return\n",
    "\n",
    "    if csv_file:\n",
    "        full_csv_url = f'{base_url}{csv_file}'\n",
    "        response = requests.get(full_csv_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Manual content inspection\n",
    "        if b\"<html\" in response.content[:500].lower():\n",
    "            # If It's HTML, manually search versions\n",
    "            version = 5\n",
    "            last_successful_response = None\n",
    "            last_successful_file = None\n",
    "\n",
    "            while True:\n",
    "                file_name = f'recs{year}_public_v{version}.csv'\n",
    "                real_csv_url = f'https://www.eia.gov/consumption/residential/data/{year}/csv/{file_name}'\n",
    "                test_response = requests.get(real_csv_url)\n",
    "\n",
    "                if test_response.status_code != 200 or b\"<html\" in test_response.content[:500].lower():\n",
    "                    # Version {version} not found or invalid\n",
    "                    break\n",
    "                else:\n",
    "                    # Save last successful version\n",
    "                    last_successful_response = test_response\n",
    "                    last_successful_file = file_name\n",
    "                    version += 1  # Keep trying next version\n",
    "\n",
    "            if last_successful_response and last_successful_file:\n",
    "                csv_path = os.path.join(base_path, last_successful_file)\n",
    "                with open(csv_path, 'wb') as f:\n",
    "                    f.write(last_successful_response.content)\n",
    "                print(f\"‚úÖ Downloaded {last_successful_file}\")\n",
    "            else:\n",
    "                print(\"‚ùå Could not find any working RECS public CSV version.\")\n",
    "                return\n",
    "\n",
    "        else:\n",
    "            # Normal CSV download\n",
    "            csv_path = os.path.join(base_path, os.path.basename(csv_file))\n",
    "            with open(csv_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ Downloaded {os.path.basename(csv_file)}\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not find RECS microdata zip or CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Download codebook separately if found\n",
    "    if codebook_file:\n",
    "        full_codebook_url = f'{base_url}{codebook_file}'\n",
    "        response = requests.get(full_codebook_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' in response.headers.get('Content-Type', ''):\n",
    "            codebook_path = os.path.join(base_path, os.path.basename(codebook_file))\n",
    "            with open(codebook_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ Downloaded {os.path.basename(codebook_file)}\")\n",
    "        else:\n",
    "            print(\"‚ùå Codebook URL did not return an XLSX file.\")\n",
    "    else:\n",
    "        print(\"‚ùå No codebook file found.\")\n",
    "\n",
    "# ========================\n",
    "# Download SEDS Data Files\n",
    "# ========================\n",
    "def download_seds_files():\n",
    "    seds_url = 'https://www.eia.gov/state/seds/seds-data-complete.php?sid=US'\n",
    "    soup = BeautifulSoup(requests.get(seds_url).text, 'html.parser')\n",
    "\n",
    "    # Extract latest year from heading\n",
    "    match = re.search(r'1960-(\\d{4})', soup.get_text())\n",
    "    if not match:\n",
    "        raise ValueError(\"‚ùå Could not find the latest SEDS year.\")\n",
    "    latest_year = match.group(1)\n",
    "    print(f\"Latest SEDS year: {latest_year}\")\n",
    "    print(f'üìÇ Saving to STAT 390 Project/Energy Data/SEDS/{latest_year}')\n",
    "\n",
    "    base_path = os.path.join('STAT 390 Project', 'Energy Data', 'SEDS', latest_year)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    # Download main CSV\n",
    "    csv_url = next(\n",
    "        (urljoin('https://www.eia.gov', a['href']) for a in soup.find_all('a', string='CSV') \n",
    "         if 'complete' in a['href'].lower() and 'seds' in a['href'].lower()), None)\n",
    "    if not csv_url:\n",
    "        raise ValueError(\"‚ùå Could not find Complete_SEDS.csv\")\n",
    "    csv_path = os.path.join(base_path, os.path.basename(csv_url))\n",
    "    with open(csv_path, 'wb') as f:\n",
    "        f.write(requests.get(csv_url).content)\n",
    "    print(f\"‚úÖ Downloaded SEDS CSV file\")\n",
    "\n",
    "    # Download codes/descriptions\n",
    "    notes_url = 'https://www.eia.gov/state/seds/seds-technical-notes-complete.php?sid=US'\n",
    "    soup = BeautifulSoup(requests.get(notes_url).text, 'html.parser')\n",
    "    code_url = next(\n",
    "        (urljoin('https://www.eia.gov', a['href']) for a in soup.find_all('a', string='CSV') \n",
    "         if 'codes' in a['href'].lower() and 'descriptions' in a['href'].lower()), None)\n",
    "    if not code_url:\n",
    "        raise ValueError(\"‚ùå Could not find codes/descriptions file.\")\n",
    "    code_path = os.path.join(base_path, os.path.basename(code_url))\n",
    "    with open(code_path, 'wb') as f:\n",
    "        f.write(requests.get(code_url).content)\n",
    "    print(f\"‚úÖ Downloaded SEDS Codes and Descriptions\")\n",
    "\n",
    "# ==============================\n",
    "# Download Total Energy Data Set\n",
    "# ==============================\n",
    "def download_total_energy_files():\n",
    "    base_url = 'https://www.eia.gov/totalenergy/data/monthly/index.php'\n",
    "    soup = BeautifulSoup(requests.get(base_url).text, 'html.parser')\n",
    "\n",
    "    # Extract the release year from page text\n",
    "    match = re.search(r'Release Date:\\s+\\w+\\s+\\d{1,2},\\s+(\\d{4})', soup.get_text())\n",
    "    if not match:\n",
    "        raise ValueError(\"‚ùå Could not find release year.\")\n",
    "    year = match.group(1)\n",
    "    print(f\"Latest Total Energy release year: {year}\")\n",
    "    print(f'üìÇ Saving to STAT 390 Project/Energy Data/ATB/{year}')\n",
    "\n",
    "    base_path = os.path.join('STAT 390 Project', 'Energy Data', 'Total Energy', year)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    # Download ZIP directly to memory\n",
    "    zip_tag = soup.find('a', string=re.compile(r'Download all tables ZIP', re.IGNORECASE))\n",
    "    if not zip_tag or not zip_tag.get('href'):\n",
    "        raise ValueError(\"‚ùå ZIP file link not found.\")\n",
    "    zip_url = urljoin(base_url, zip_tag['href'])\n",
    "\n",
    "    try:\n",
    "        zip_response = requests.get(zip_url)\n",
    "        zip_response.raise_for_status()\n",
    "        zip_bytes = io.BytesIO(zip_response.content)\n",
    "\n",
    "        with zipfile.ZipFile(zip_bytes) as zip_ref:\n",
    "            for member in zip_ref.infolist():\n",
    "                if member.filename.endswith('/') or not member.filename.lower().endswith('.xlsx'):\n",
    "                    continue  # Skip folders and non-Excel files\n",
    "\n",
    "                # Read Excel file from ZIP directly\n",
    "                xlsx_data = zip_ref.read(member)\n",
    "                xlsx_buffer = io.BytesIO(xlsx_data)\n",
    "                xlsx_name = os.path.splitext(os.path.basename(member.filename))[0]\n",
    "\n",
    "                try:\n",
    "                    wb = openpyxl.load_workbook(xlsx_buffer, data_only=True)\n",
    "                    sheetnames = wb.sheetnames\n",
    "                \n",
    "                    if \"Annual Data\" in sheetnames:\n",
    "                        # Only process \"Annual Data\" sheet\n",
    "                        sheet = wb[\"Annual Data\"]\n",
    "                \n",
    "                        # Read from the sheet starting from the correct position\n",
    "                        label = sheet['A7'].value or 'unknown'\n",
    "                        label_clean = re.sub(r'[^\\w\\- ]+', '', str(label)).replace(' ', '_').lower()\n",
    "                \n",
    "                        csv_filename = f\"{label_clean}.csv\"  # ‚ùó no prefix like \"annual_data\" anymore\n",
    "                        # If it starts with \"table_\", remove \"table_xxx_\" prefix\n",
    "                        if csv_filename.startswith('table_'):\n",
    "                            # Find the first underscore after \"table_\", then strip up to there\n",
    "                            parts = csv_filename.split('_', 2)  # Split into at most 3 parts: \"table\", \"xxx\", \"rest\"\n",
    "                            if len(parts) == 3:\n",
    "                                csv_filename = parts[2]  # Keep only \"rest\"\n",
    "                        \n",
    "                        # Prepend \"total_energy_\" no matter what\n",
    "                        csv_filename = f\"total_energy_{csv_filename}\"\n",
    "                        csv_path = os.path.join(base_path, csv_filename)\n",
    "                \n",
    "                        with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "                            writer = csv.writer(f)\n",
    "                            for row in sheet.iter_rows(values_only=True):\n",
    "                                writer.writerow(row)\n",
    "                \n",
    "                        print(f\"‚úÖ Downloaded Total Energy Data: {csv_filename}\")\n",
    "                \n",
    "                    else:\n",
    "                        # If no \"Annual Data\" sheet, process all sheets individually (ignoring monthly)\n",
    "                        for sheet_name in sheetnames:\n",
    "                            if \"monthly\" in sheet_name.lower():\n",
    "                                continue  # ‚ùó skip any monthly data\n",
    "                \n",
    "                            sheet = wb[sheet_name]\n",
    "                \n",
    "                            # Clean the sheet name for the filename\n",
    "                            label_clean = re.sub(r'[^\\w\\- ]+', '', sheet_name).replace(' ', '_').lower()\n",
    "                \n",
    "                            csv_filename = f\"{label_clean}.csv\"  # ‚ùó clean filename\n",
    "                            # If it starts with \"table_\", remove \"table_xxx_\" prefix\n",
    "                            if csv_filename.startswith('table_'):\n",
    "                                # Find the first underscore after \"table_\", then strip up to there\n",
    "                                parts = csv_filename.split('_', 2)  # Split into at most 3 parts: \"table\", \"xxx\", \"rest\"\n",
    "                                if len(parts) == 3:\n",
    "                                    csv_filename = parts[2]  # Keep only \"rest\"\n",
    "                            \n",
    "                            # Prepend \"total_energy_\" no matter what\n",
    "                            csv_filename = f\"total_energy_{csv_filename}\"\n",
    "                            csv_path = os.path.join(base_path, csv_filename)\n",
    "                \n",
    "                            with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "                                writer = csv.writer(f)\n",
    "                                for row in sheet.iter_rows(values_only=True):\n",
    "                                    writer.writerow(row)\n",
    "                \n",
    "                            print(f\"‚úÖ Downloaded Total Energy Data: {csv_filename}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to process {member.filename}: {e}\")\n",
    "                \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed to download ZIP archive: {e}\")\n",
    "        return\n",
    "\n",
    "    # Download Glossary PDF\n",
    "    pdf_tag = soup.find('a', href=re.compile(r'PDF', re.IGNORECASE), attrs={'title': 'Glossary'})\n",
    "    if not pdf_tag or not pdf_tag.get('href'):\n",
    "        raise ValueError(\"‚ùå Glossary PDF not found.\")\n",
    "    pdf_url = urljoin(base_url, pdf_tag['href'])\n",
    "    pdf_path = os.path.join(base_path, os.path.basename(pdf_url))\n",
    "\n",
    "    try:\n",
    "        with open(pdf_path, 'wb') as f:\n",
    "            f.write(requests.get(pdf_url).content)\n",
    "        print(f\"‚úÖ Downloaded Total Energy Glossary PDF\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download Glossary PDF: {e}\")\n",
    "\n",
    "# ===========================================\n",
    "# Download Latest ATB Workbook & Documentation\n",
    "# ===========================================\n",
    "def download_atb_files():\n",
    "    base_path_root = os.path.join('STAT 390 Project', 'Energy Data', 'ATB')\n",
    "    base_url_template = 'https://atb.nrel.gov/electricity/{year}/data'\n",
    "    doc_url = 'https://raw.githubusercontent.com/openEDI/documentation/main/ATB.md'\n",
    "\n",
    "    latest_year = None\n",
    "    for year in range(2025, 2014, -1):\n",
    "        url = base_url_template.format(year=year)\n",
    "        try:\n",
    "            if requests.head(url, allow_redirects=True, timeout=5).status_code == 200:\n",
    "                latest_year = str(year)\n",
    "                break\n",
    "        except requests.RequestException:\n",
    "            continue\n",
    "    if not latest_year:\n",
    "        raise ValueError(\"‚ùå No valid ATB year found.\")\n",
    "    print(f\"Latest ATB year: {latest_year}\")\n",
    "    print(f'üìÇ Saving to STAT 390 Project/Energy Data/ATB/{latest_year}')\n",
    "\n",
    "    base_path = os.path.join(base_path_root, latest_year)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(base_url_template.format(year=latest_year)).text, 'html.parser')\n",
    "    csv_tag = soup.find('a', string=re.compile(rf'Download the {latest_year} ATB Summary CSV Files', re.IGNORECASE))\n",
    "    if not csv_tag or not csv_tag.get('href'):\n",
    "        raise ValueError(\"‚ùå ATB Summary CSV not found.\")\n",
    "    csv_url = urljoin(base_url_template.format(year=latest_year), csv_tag['href'])\n",
    "    csv_path = os.path.join(base_path, os.path.basename(csv_url))\n",
    "    with open(csv_path, 'wb') as f:\n",
    "        f.write(requests.get(csv_url).content)\n",
    "    print(f\"‚úÖ Downloaded ATB Summary CSV\")\n",
    "\n",
    "    doc_path = os.path.join(base_path, 'ATB.md')\n",
    "    with open(doc_path, 'wb') as f:\n",
    "        f.write(requests.get(doc_url).content)\n",
    "    print(f\"‚úÖ Downloaded ATB Documentation\")\n",
    "\n",
    "# ============================\n",
    "# Download RMI Dataset Files\n",
    "# ============================\n",
    "def download_rmi_files():\n",
    "    base_url = 'https://utilitytransitionhub.rmi.org/data-download/'\n",
    "    base_dir = os.path.join('STAT 390 Project', 'Energy Data', 'RMI')\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    # Files to keep (original base names)\n",
    "    keep_basenames = [\n",
    "        'employees',\n",
    "        'operations_emissions_by_fuel',\n",
    "        'revenue_by_tech',\n",
    "        'utility_state_map'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(base_url).text, 'html.parser')\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed to retrieve RMI page: {e}\")\n",
    "        return\n",
    "\n",
    "    print('üìÇ Saving to STAT 390 Project/Energy Data/RMI')\n",
    "\n",
    "    containers = soup.find_all('div', class_='container mb-16')[0]\n",
    "    for container in containers:\n",
    "        # Extract \"Last updated\" year\n",
    "        match = re.search(r'Last updated:\\s+\\w+\\s+\\d{1,2},\\s+(\\d{4})', container.get_text())\n",
    "        modified_year = match.group(1) if match else 'unknown'\n",
    "\n",
    "        for a in container.find_all('a', href=True):\n",
    "            file_url = urljoin(base_url, a['href'])\n",
    "            file_name = os.path.basename(file_url)\n",
    "\n",
    "            # Only process if .csv, .xlsx, or .zip\n",
    "            if not re.search(r'\\.(csv|xlsx|zip)$', file_name, re.IGNORECASE):\n",
    "                continue\n",
    "\n",
    "            base, ext = os.path.splitext(file_name)\n",
    "            base_lower = base.lower()\n",
    "\n",
    "            # Skip if not in keep list\n",
    "            if not any(target in base_lower for target in keep_basenames):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                response = requests.get(file_url)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Handle zip extraction in memory\n",
    "                if ext.lower() == '.zip':\n",
    "                    zip_bytes = io.BytesIO(response.content)\n",
    "                    try:\n",
    "                        with zipfile.ZipFile(zip_bytes, 'r') as zip_ref:\n",
    "                            for member in zip_ref.infolist():\n",
    "                                if member.filename.endswith('/'):\n",
    "                                    continue  # Skip folders\n",
    "                                inner_name = os.path.basename(member.filename)\n",
    "                                inner_base, inner_ext = os.path.splitext(inner_name)\n",
    "\n",
    "                                # Check again inside zip\n",
    "                                inner_base_lower = inner_base.lower()\n",
    "                                if not any(target in inner_base_lower for target in keep_basenames):\n",
    "                                    continue\n",
    "\n",
    "                                # Add year if not already present\n",
    "                                if not re.search(r'\\d{4}$', inner_base):\n",
    "                                    inner_name = f\"{inner_base}_{modified_year}{inner_ext}\"\n",
    "\n",
    "                                file_path = os.path.join(base_dir, inner_name)\n",
    "                                with zip_ref.open(member) as source, open(file_path, 'wb') as target:\n",
    "                                    target.write(source.read())\n",
    "                                print(f\"‚úÖ Downloaded RMI Data: {inner_name}\")\n",
    "                    except zipfile.BadZipFile:\n",
    "                        print(f\"‚ùå Invalid ZIP: {file_name}\")\n",
    "                else:\n",
    "                    # Non-zip file\n",
    "                    if not re.search(r'\\d{4}$', base):\n",
    "                        file_name = f\"{base}_{modified_year}{ext}\"\n",
    "                    file_path = os.path.join(base_dir, file_name)\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    print(f\"‚úÖ Downloaded RMI Data: {file_name}\")\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"‚ùå Failed to download RMI Data: {file_url}: {e}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print('Downloading Energy Data ...')\n",
    "        print('--------------------------------------------------------')\n",
    "        download_recs_files()\n",
    "        print('--------------------------------------------------------')\n",
    "        download_seds_files()\n",
    "        print('--------------------------------------------------------')\n",
    "        download_total_energy_files()\n",
    "        print('--------------------------------------------------------')\n",
    "        download_atb_files()\n",
    "        print('--------------------------------------------------------')\n",
    "        download_rmi_files()\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b929857-6066-4bd9-aef3-6e7684cfbeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Energy Data ...\n",
      "--------------------------------------------------------\n",
      "üìÇ Saving to STAT 390 Project\\Energy Data\\RECS\\2020\n",
      "‚úÖ Downloaded recs2020_public_v7.csv\n",
      "‚úÖ Downloaded RECS 2020 Codebook for Public File - v7.xlsx\n",
      "--------------------------------------------------------\n",
      "Latest SEDS year: 2022\n",
      "üìÇ Saving to STAT 390 Project/Energy Data/SEDS/2022\n",
      "‚úÖ Downloaded SEDS CSV file\n",
      "‚úÖ Downloaded SEDS Codes and Descriptions\n",
      "--------------------------------------------------------\n",
      "Latest Total Energy release year: 2025\n",
      "üìÇ Saving to STAT 390 Project/Energy Data/ATB/2025\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_production_by_source.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_consumption_by_source.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_imports_by_source.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_exports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_net_imports_by_source.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_merchandise_trade_value.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_cost_of_fuels_to_end_users_in_real_1982-1984_dollars.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_consumption_energy_expenditures_and_carbon_dioxide_emissions_indicators.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_motor_vehicle_mileage_fuel_consumption_and_fuel_economy.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_light-duty_vehicle_average_miles_traveled_by_technology_type.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_and_fuel_cell_electric_light-duty_vehicles_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_heating_degree-days_by_census_division.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_cooling_degree-days_by_census_division.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_non-combustion_use_of_fossil_fuels_in_physical_units.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_heat_content_of_non-combustion_use_of_fossil_fuels.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_energy_consumption_residential_commercial_and_industrial_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_energy_consumption_transportation_sector_total_end-use_sectors_and_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_residential_sector_energy_consumption.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_commercial_sector_energy_consumption.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_industrial_sector_energy_consumption.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_transportation_sector_energy_consumption.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_power_sector_energy_consumption.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy__us_government_energy_consumption_by_agency_fiscal_years.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy__us_government_energy_consumption_by_source_fiscal_years.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_refinery_and_blender_net_inputs_and_net_production.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_trade_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_imports_and_exports_by_type.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_imports_from_opec_countries.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_imports_from_non-opec_countries.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_exports_by_type.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_exports_by_country_of_destination.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_stocks.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_products_supplied_by_type.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_heat_content_of_petroleum_products_supplied_by_type.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_residential_and_commercial_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_industrial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_transportation_and_electric_power_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_residential_and_commercial_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_industrial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_transportation_and_electric_power_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_imports_by_country.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_exports_by_country.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_by_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_underground_storage.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_drilling_activity_measurements.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_wells_and_footage_drilled.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_by_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_stocks_by_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electricity_net_generation_total_all_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electricity_net_generation_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electricity_net_generation_commercial_and_industrial_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_of_combustible_fuels_for_electricity_generation_total_all_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_of_combustible_fuelsfor_electricity_generation_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_of_combustible_fuelsfor_electricity_generation_commercial_and_industrial_sectors_selected_fuels.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_of_combustible_fuels_for_electricity_generation_and_useful_thermal_output_total_all_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_of_combustible_fuels_for_electricity_generation_and_useful_thermal_output_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_of_combustible_fuels_for_electricity_generation_and_useful_thermal_output_commercial_and_industrial_sectors_selected_fuels.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_stocks_of_coal_and_petroleum_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electricity_end_use_and_electric_vehicle_use.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_net_summer_capacity_total_all_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_net_summer_capacity_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_net_summer_capacity_commercial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_net_summer_capacity_industrial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_capacity_factors_and_usage_factors_at_electric_generators_total_all_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_capacity_factors_and_usage_factors_at_electric_generators_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_capacity_factors_and_usage_factors_at_electric_generators_commercial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_capacity_factors_and_usage_factors_at_electric_generators_industrial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_nuclear_energy_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_uranium_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_crude_oil_price_summary.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_fob_costs_of_crude_oil_imports_from_selected_countries.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_landed_costs_of_crude_oil_imports_from_selected_countries.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_retail_motor_gasoline_and_on-highway_diesel_fuel_prices.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_refiner_prices_of_residual_fuel_oil.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_refiner_prices_of_petroleum_products_for_resale.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_refiner_prices_of_petroleum_products_to_end_users.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_average_prices_of_electricity_to_ultimate_customers.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_cost_of_fossil-fuel_receipts_at_electric_generating_plants.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_natural_gas_prices.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_production_and_consumption_by_source.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_residential_and_commercial_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_industrial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_consumption_transportation_and_electric_power_sectors.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_fuel_ethanol_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_biodiesel_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_renewable_diesel_fuel_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_other_biofuels_overview.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_solar_energy_consumption.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_solar_electricity_net_generation.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_by_source.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_residential_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_commercial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_industrial_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_transportation_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_electric_power_sector.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_carbon_dioxide_emissions_from_energy_consumption_biomass.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_petroleum_production_imports_and_exports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_petroleum_consumption_and_fuel_ethanol.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_natural_gas.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_coal_and_coal_coke.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_approximate_heat_rates_for_electricity.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_population_us_gross_domestic_product_and_us_gross_output.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_overview_fossil_fuel_equivalency_approach.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_production_by_source_fossil_fuel_equivalency_approach.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_primary_energy_consumption_by_source_fossil_fuel_equivalency_approach.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_renewable_energy_production_and_consumption_by_source_fossil_fuel_equivalency_approach.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_electric_vehicle_charging_infrastructure.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_contents.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_public_ports_only.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_private_ports_only.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_public__private_ports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_networked_ports_only.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_non-networked_ports_only.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_networked__non-networked_port.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_total_locations.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_dc_fast_charging_ports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_level_2_charging_ports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_level_1_charging_ports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_legacy_charging_ports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_total_ports.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_dcfc_ports_per_location.csv\n",
      "‚úÖ Downloaded Total Energy Data: total_energy_l2_charging_ports_per_location.csv\n",
      "‚úÖ Downloaded Total Energy Glossary PDF\n",
      "--------------------------------------------------------\n",
      "Latest ATB year: 2024\n",
      "üìÇ Saving to STAT 390 Project/Energy Data/ATB/2024\n",
      "‚úÖ Downloaded ATB Summary CSV\n",
      "‚úÖ Downloaded ATB Documentation\n",
      "--------------------------------------------------------\n",
      "üìÇ Saving to STAT 390 Project/Energy Data/RMI\n",
      "‚úÖ Downloaded RMI Data: employees_2022.csv\n",
      "‚úÖ Downloaded RMI Data: operations_emissions_by_fuel_2024.csv\n",
      "‚úÖ Downloaded RMI Data: revenue_by_tech_2022.csv\n",
      "‚úÖ Downloaded RMI Data: utility_state_map_2022.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95fa83-029c-4190-a1d5-cf2fc1674d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
