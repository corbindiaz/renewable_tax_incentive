{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cbf0cc6-9b46-42d6-bc3f-24b43e61b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "# Set base folders\n",
    "energy_data_folder = 'STAT 390 Project/Energy Data'\n",
    "states = [\n",
    "    'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "    'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "    'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "    'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "    'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Load ATB Data\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_atb():\n",
    "    atb_folder = os.path.join(energy_data_folder, 'ATB')\n",
    "    years = [f for f in os.listdir(atb_folder) if f.isdigit()]\n",
    "    latest_year = max(years)\n",
    "    atb_path = os.path.join(atb_folder, latest_year)\n",
    "\n",
    "    csv_files = [f for f in os.listdir(atb_path) if f.endswith('.csv')]\n",
    "    if not csv_files:\n",
    "        raise ValueError(f\"❌ No CSV files found in {atb_path}\")\n",
    "\n",
    "    atb_file = os.path.join(atb_path, csv_files[0])\n",
    "    print(f\"✅ Loading ATB file: {atb_file}\")\n",
    "\n",
    "    atb_df = pd.read_csv(atb_file, low_memory=False, index_col=0).reset_index(drop=True)\n",
    "\n",
    "    # Confirm year column\n",
    "    first_col = atb_df.columns[0]\n",
    "    if 'year' not in first_col.lower():\n",
    "        raise ValueError(f\"❌ First column '{first_col}' does not contain 'year'.\")\n",
    "\n",
    "    # Step 1: Remove 'default' column (no longer needed)\n",
    "    atb_df = atb_df.drop(columns=['default'])\n",
    "\n",
    "    # Step 2: Create final metadata dict per row\n",
    "    metadata_rows = []\n",
    "    for _, row in atb_df.iterrows():\n",
    "        year = row[first_col]\n",
    "        metadata = row.drop(first_col).to_dict()\n",
    "\n",
    "        metadata_rows.append({\n",
    "            'year': int(year),\n",
    "            'state': 'US',\n",
    "            'metadata': {'ATB': metadata}\n",
    "        })\n",
    "\n",
    "    # Step 3: Build final DataFrame\n",
    "    final_atb_df = pd.DataFrame(metadata_rows)\n",
    "\n",
    "    print(\"✅ Final ATB metadata dataframe ready!\")\n",
    "    return final_atb_df\n",
    "\n",
    "# =========================\n",
    "# Load RECS Data\n",
    "# =========================\n",
    "\n",
    "def load_recs():\n",
    "    recs_folder = os.path.join(energy_data_folder, 'RECS')\n",
    "    years = [f for f in os.listdir(recs_folder) if f.isdigit()]\n",
    "    latest_year = max(years)\n",
    "    saved_year = int(latest_year)\n",
    "    recs_path = os.path.join(recs_folder, latest_year)\n",
    "\n",
    "    recs_files = [f for f in os.listdir(recs_path) if f.endswith('.csv') and 'recs' in f.lower()]\n",
    "    version_files = []\n",
    "    for f in recs_files:\n",
    "        match = re.search(r'v(\\d+)', f.lower())\n",
    "        if match:\n",
    "            version_files.append((int(match.group(1)), f))\n",
    "    if not version_files:\n",
    "        raise ValueError(f\"❌ No RECS files with version found in {recs_path}\")\n",
    "\n",
    "    highest_version_file = max(version_files, key=lambda x: x[0])[1]\n",
    "    recs_file = os.path.join(recs_path, highest_version_file)\n",
    "    print(f\"✅ Loading RECS file: {recs_file}\")\n",
    "\n",
    "    # Load RECS file\n",
    "    recs_df = pd.read_csv(recs_file, low_memory=False)\n",
    "\n",
    "    if 'state_postal' not in recs_df.columns:\n",
    "        raise ValueError(\"❌ 'state_postal' column missing in RECS file\")\n",
    "\n",
    "    # Rename for clarity\n",
    "    recs_df = recs_df.rename(columns={'state_postal': 'state'})\n",
    "\n",
    "    # Step 1: Create metadata dictionaries\n",
    "    metadata_rows = []\n",
    "    for _, row in recs_df.iterrows():\n",
    "        state = row['state']\n",
    "        metadata = row.drop('state').to_dict()\n",
    "\n",
    "        # Overwrite/add year manually to be safe\n",
    "        metadata['year'] = saved_year\n",
    "\n",
    "        metadata_rows.append({\n",
    "            'year': saved_year,\n",
    "            'state': state,\n",
    "            'metadata': {'RECS': metadata}\n",
    "        })\n",
    "\n",
    "    # Step 2: Build final DataFrame\n",
    "    final_recs_df = pd.DataFrame(metadata_rows)\n",
    "\n",
    "    print(\"✅ Final RECS metadata dataframe ready!\")\n",
    "    return final_recs_df\n",
    "\n",
    "# =========================\n",
    "# Load RMI Operations Emissions\n",
    "# =========================\n",
    "\n",
    "def load_rmi():\n",
    "    # --- Setup ---\n",
    "    rmi_folder = os.path.join(energy_data_folder, 'RMI')\n",
    "\n",
    "    # Find operations file\n",
    "    operations_files = [f for f in os.listdir(rmi_folder) if 'operations_emissions_by_fuel' in f.lower()]\n",
    "    if not operations_files:\n",
    "        raise ValueError(\"❌ No RMI operations_emissions_by_fuel file found.\")\n",
    "\n",
    "    operations_path = os.path.join(rmi_folder, operations_files[0])\n",
    "    print(f\"✅ Loading RMI Operations file: {operations_path}\")\n",
    "\n",
    "    # --- Load the file ---\n",
    "    operations_df = pd.read_csv(operations_path, dtype=str)\n",
    "\n",
    "    # --- Minimal cleaning ---\n",
    "    numeric_columns = operations_df.columns[-5:]  # last 5 numeric columns\n",
    "    keep_columns = ['year', 'state', 'fuel_type_category'] + list(numeric_columns)\n",
    "\n",
    "    operations_clean = operations_df[keep_columns].copy()\n",
    "\n",
    "    # Convert numeric columns\n",
    "    for col in numeric_columns:\n",
    "        operations_clean[col] = pd.to_numeric(operations_clean[col], errors='coerce')\n",
    "\n",
    "    # --- Group by year, state, fuel ---\n",
    "    grouped = operations_clean.groupby(['year', 'state', 'fuel_type_category'], as_index=False).sum()\n",
    "\n",
    "    # --- Pivot into wide format ---\n",
    "    reshaped_list = []\n",
    "    for metric in numeric_columns:\n",
    "        pivot = grouped.pivot_table(\n",
    "            index=['year', 'state'],\n",
    "            columns='fuel_type_category',\n",
    "            values=metric,\n",
    "            aggfunc='sum'\n",
    "        )\n",
    "        pivot = pivot.add_prefix(f'{metric}_')\n",
    "        reshaped_list.append(pivot)\n",
    "\n",
    "    operations_wide = pd.concat(reshaped_list, axis=1).reset_index()\n",
    "    operations_wide.columns.name = None  # remove extra axis name\n",
    "\n",
    "    # --- Build metadata column ---\n",
    "    def pack_metadata(row):\n",
    "        return {'RMI': {col: row[col] for col in operations_wide.columns if col not in ['year', 'state']}}\n",
    "\n",
    "    final_df = pd.DataFrame({\n",
    "        'year': operations_wide['year'].astype(int),\n",
    "        'state': operations_wide['state'],\n",
    "        'metadata': operations_wide.apply(pack_metadata, axis=1)\n",
    "    })\n",
    "\n",
    "    print(f\"✅ Final RMI operations metadata dataframe ready!\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load Total Energy Data\n",
    "# =========================\n",
    "\n",
    "def load_total_energy():\n",
    "    total_folder = os.path.join(energy_data_folder, 'Total Energy/2025')\n",
    "    files = [f for f in os.listdir(total_folder) if f.endswith('.csv') and f != 'total_energy_contents.csv']\n",
    "    all_dfs = []\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(total_folder, file_name)\n",
    "    \n",
    "        try:\n",
    "            # Quick scan to detect if 'YYYYMM' format appears (in 3rd row)\n",
    "            preview = pd.read_csv(file_path, nrows=5, header=None, dtype=str)\n",
    "            header_preview = preview.iloc[2].fillna('').tolist()\n",
    "    \n",
    "            first_col = header_preview[0]\n",
    "    \n",
    "            if 'yyyymm' in str(first_col).lower():\n",
    "                # ✅ State-organized special case\n",
    "    \n",
    "                # Step 1: Read with header at 3rd row (skip first 2 rows)\n",
    "                df = pd.read_csv(file_path, skiprows=2, dtype=str)\n",
    "    \n",
    "                # Step 2: Clean header\n",
    "                df.columns = [col.replace(',', '').strip() if isinstance(col, str) else col for col in df.columns]\n",
    "    \n",
    "                # Step 3: Drop 'US' column if it exists\n",
    "                df = df.drop(columns=['US'], errors='ignore')\n",
    "    \n",
    "                # Step 4: Reformat 'YYYYMM' to 'YYYY'\n",
    "                original_year_col = df.columns[0]\n",
    "                df[original_year_col] = df[original_year_col].str[:4]\n",
    "                df = df.rename(columns={original_year_col: 'year'})\n",
    "    \n",
    "                # Step 5: Melt into long format\n",
    "                value_col_name = file_name.replace('.csv', '').lower()\n",
    "                df_melted = df.melt(id_vars=['year'], var_name='state', value_name=value_col_name)\n",
    "    \n",
    "                # Step 6: Convert values to numeric\n",
    "                df_melted[value_col_name] = pd.to_numeric(df_melted[value_col_name], errors='coerce')\n",
    "    \n",
    "                # Step 7: Group by (year, state) and take sum\n",
    "                df_grouped = df_melted.groupby(['year', 'state'], as_index=True).sum()\n",
    "    \n",
    "                # Step 8: Sort (optional polish)\n",
    "                df_grouped = df_grouped.sort_index()\n",
    "    \n",
    "                # Add to the list\n",
    "                all_dfs.append(df_grouped)\n",
    "    \n",
    "                print(f\"✅ Processed file: {file_name}\")\n",
    "    \n",
    "            else:\n",
    "                # ✅ Normal file case\n",
    "    \n",
    "                # Step 1: Read header rows manually\n",
    "                df_header1 = pd.read_csv(file_path, skiprows=8, nrows=1, header=None, dtype=str)\n",
    "                df_header2 = pd.read_csv(file_path, skiprows=9, nrows=1, header=None, dtype=str)\n",
    "    \n",
    "                # Step 2: Combine headers\n",
    "                combined_headers = []\n",
    "                for h1, h2 in zip(df_header1.iloc[0], df_header2.iloc[0]):\n",
    "                    h1_clean = str(h1).strip().replace(',', '').replace(' ', '_').lower()\n",
    "                    h2_clean = str(h2).strip().replace(',', '').replace(' ', '_').lower()\n",
    "                    if h2_clean and h2_clean.lower() != 'nan':\n",
    "                        combined_headers.append(f\"{h1_clean}_{h2_clean}\")\n",
    "                    else:\n",
    "                        combined_headers.append(h1_clean)\n",
    "    \n",
    "                # Step 3: Read full data\n",
    "                df = pd.read_csv(file_path, skiprows=10, names=combined_headers, dtype=str)\n",
    "    \n",
    "                # Step 4: Clean column names\n",
    "                col_a_original = combined_headers[0]\n",
    "    \n",
    "                # Step 5: Rename first column to 'year'\n",
    "                df = df.rename(columns={col_a_original: 'year'})\n",
    "    \n",
    "                # Step 6: Rename other columns properly\n",
    "                cleaned_columns = {}\n",
    "                for col in df.columns:\n",
    "                    if col != 'year':\n",
    "                        cleaned_columns[col] = f\"{file_name.replace('.csv', '').lower()}_{col}_{col_a_original}\"\n",
    "                df = df.rename(columns=cleaned_columns)\n",
    "    \n",
    "                df['state'] = 'US'\n",
    "                df = df.set_index(['year', 'state'])\n",
    "    \n",
    "                all_dfs.append(df)\n",
    "    \n",
    "                print(f\"✅ Processed file: {file_name}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process {file_name}: {e}\")\n",
    "    \n",
    "    # Merge all DataFrames efficiently\n",
    "    if all_dfs:\n",
    "        final_df = reduce(lambda left, right: left.join(right, how='outer'), all_dfs)\n",
    "        final_df = final_df.sort_index()\n",
    "    \n",
    "        print(\"✅ Final Total Energy dataframe ready!\")\n",
    "    \n",
    "    else:\n",
    "        final_df = pd.DataFrame()\n",
    "        print(\"❌ No data was loaded.\")\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# =========================\n",
    "# Load SEDS Data\n",
    "# =========================\n",
    "\n",
    "def load_seds():\n",
    "    seds_folder = os.path.join(energy_data_folder, 'SEDS')\n",
    "    years = [f for f in os.listdir(seds_folder) if f.isdigit()]\n",
    "    latest_year = max(years)\n",
    "    seds_path = os.path.join(seds_folder, latest_year)\n",
    "\n",
    "    csv_files = [f for f in os.listdir(seds_path) if f.endswith('.csv') and 'complete' in f.lower()]\n",
    "    if not csv_files:\n",
    "        raise ValueError(f\"❌ No 'complete' CSV files found in {seds_path}\")\n",
    "\n",
    "    seds_file = os.path.join(seds_path, csv_files[0])\n",
    "    print(f\"✅ Loading SEDS file: {seds_file}\")\n",
    "\n",
    "    seds_df = pd.read_csv(seds_file, low_memory=False)\n",
    "\n",
    "    if 'Data_Status' in seds_df.columns:\n",
    "        seds_df = seds_df.drop(columns=['Data_Status'])\n",
    "\n",
    "    seds_pivoted = seds_df.pivot_table(index=['Year', 'StateCode'], columns='MSN', values='Data').reset_index()\n",
    "    seds_pivoted.columns.name = None\n",
    "    seds_pivoted = seds_pivoted.rename(columns={'Year': 'year', 'StateCode': 'state'})\n",
    "    final_seds_df = seds_pivoted.set_index(['year', 'state'])\n",
    "\n",
    "    print(\"✅ Final SEDS dataframe ready!\")\n",
    "    return final_seds_df\n",
    "\n",
    "# =========================\n",
    "# Merge Total Energy & SEDS\n",
    "# =========================\n",
    "\n",
    "def merge_seds_and_total(seds_df, total_df):\n",
    "    # 🛠 Step 1: Standardize both datasets\n",
    "    def standardize_index(df):\n",
    "        if isinstance(df.index, pd.MultiIndex):\n",
    "            df = df.reset_index()\n",
    "        else:\n",
    "            df = df.reset_index()\n",
    "\n",
    "        if 'year' not in df.columns or 'state' not in df.columns:\n",
    "            raise ValueError(\"❌ DataFrame missing 'year' or 'state' for merging.\")\n",
    "\n",
    "        df['year'] = df['year'].astype(int)\n",
    "        df['state'] = df['state'].astype(str)\n",
    "\n",
    "        return df.set_index(['year', 'state'])\n",
    "\n",
    "    seds_std = standardize_index(seds_df)\n",
    "    total_std = standardize_index(total_df)\n",
    "\n",
    "    # 🛠 Step 2: Merge SEDS and Total Energy\n",
    "    merged = seds_std.join(total_std, how='outer')\n",
    "\n",
    "    # 🛠 Step 3: Reset index (now year and state are columns)\n",
    "    merged = merged.reset_index()\n",
    "\n",
    "    # 🛠 Step 4: Build metadata column\n",
    "    priority_cols = ['year', 'state']\n",
    "    data_cols = [col for col in merged.columns if col not in priority_cols]\n",
    "\n",
    "    def row_to_metadata(row):\n",
    "        metadata = {col: row[col] for col in data_cols if pd.notna(row[col])}\n",
    "        return {\"SEDS_AND_TOTAL_ENERGY\": metadata}\n",
    "\n",
    "    merged['metadata'] = merged.apply(row_to_metadata, axis=1)\n",
    "\n",
    "    # 🛠 Step 5: Keep only year, state, metadata\n",
    "    final_df = merged[['year', 'state', 'metadata']]\n",
    "\n",
    "    print(f\"✅ Merged SEDS and Total Energy it metadata dataframe\")\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "878e2ae0-9244-45f9-aeec-277e87b9599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def final_concat():\n",
    "    # 🛠 Step 1: Concatenate all datasets\n",
    "    combined_df = pd.concat([\n",
    "        atb_df,\n",
    "        recs_df,\n",
    "        rmi_df,\n",
    "        seds_and_total_df\n",
    "    ], axis=0, ignore_index=True)\n",
    "    \n",
    "    # 🗺 Step 2: State abbreviation → full state name\n",
    "    # Reference: https://www.usps.com/send/official-abbreviations.htm\n",
    "    state_abbr_to_name = {\n",
    "        'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',\n",
    "        'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',\n",
    "        'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "        'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "        'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "        'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "        'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
    "        'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',\n",
    "        'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',\n",
    "        'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
    "        'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'District of Columbia'\n",
    "    }\n",
    "    \n",
    "    # Only replace if it matches a valid abbreviation\n",
    "    combined_df['state'] = combined_df['state'].apply(\n",
    "        lambda x: state_abbr_to_name.get(x, x)  # If x is a valid abbreviation, replace; else keep as is\n",
    "    )\n",
    "    \n",
    "    # 🧹 Step 3: Optional sort\n",
    "    combined_df = combined_df.sort_values(['year', 'state']).reset_index(drop=True)\n",
    "    \n",
    "    # ✅ Done\n",
    "    print(f\"✅ Final combined dataset shape: {combined_df.shape}\")\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bbaf94ab-db50-4e13-ae53-f41317864a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading RMI Operations file: STAT 390 Project/Energy Data\\RMI\\operations_emissions_by_fuel_2024.csv\n",
      "✅ Final RMI operations metadata dataframe ready!\n",
      "✅ Loading SEDS file: STAT 390 Project/Energy Data\\SEDS\\2022\\Complete_SEDS.csv\n",
      "✅ Final SEDS dataframe ready!\n",
      "✅ Processed file: total_energy_approximate_heat_rates_for_electricity.csv\n",
      "✅ Processed file: total_energy_average_prices_of_electricity_to_ultimate_customers.csv\n",
      "✅ Processed file: total_energy_biodiesel_overview.csv\n",
      "✅ Processed file: total_energy_capacity_factors_and_usage_factors_at_electric_generators_commercial_sector.csv\n",
      "✅ Processed file: total_energy_capacity_factors_and_usage_factors_at_electric_generators_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_capacity_factors_and_usage_factors_at_electric_generators_industrial_sector.csv\n",
      "✅ Processed file: total_energy_capacity_factors_and_usage_factors_at_electric_generators_total_all_sectors.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_biomass.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_by_source.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_commercial_sector.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_industrial_sector.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_residential_sector.csv\n",
      "✅ Processed file: total_energy_carbon_dioxide_emissions_from_energy_consumption_transportation_sector.csv\n",
      "✅ Processed file: total_energy_coal_and_coal_coke.csv\n",
      "✅ Processed file: total_energy_commercial_sector_energy_consumption.csv\n",
      "✅ Processed file: total_energy_consumption_by_sector.csv\n",
      "✅ Processed file: total_energy_consumption_industrial_sector.csv\n",
      "✅ Processed file: total_energy_consumption_of_combustible_fuelsfor_electricity_generation_commercial_and_industrial_sectors_selected_fuels.csv\n",
      "✅ Processed file: total_energy_consumption_of_combustible_fuelsfor_electricity_generation_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_consumption_of_combustible_fuels_for_electricity_generation_and_useful_thermal_output_commercial_and_industrial_sectors_selected_fuels.csv\n",
      "✅ Processed file: total_energy_consumption_of_combustible_fuels_for_electricity_generation_and_useful_thermal_output_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_consumption_of_combustible_fuels_for_electricity_generation_and_useful_thermal_output_total_all_sectors.csv\n",
      "✅ Processed file: total_energy_consumption_of_combustible_fuels_for_electricity_generation_total_all_sectors.csv\n",
      "✅ Processed file: total_energy_consumption_residential_and_commercial_sectors.csv\n",
      "✅ Processed file: total_energy_consumption_transportation_and_electric_power_sectors.csv\n",
      "✅ Processed file: total_energy_cooling_degree-days_by_census_division.csv\n",
      "✅ Processed file: total_energy_cost_of_fossil-fuel_receipts_at_electric_generating_plants.csv\n",
      "✅ Processed file: total_energy_cost_of_fuels_to_end_users_in_real_1982-1984_dollars.csv\n",
      "✅ Processed file: total_energy_crude_oil_price_summary.csv\n",
      "✅ Processed file: total_energy_dcfc_ports_per_location.csv\n",
      "✅ Processed file: total_energy_dc_fast_charging_ports.csv\n",
      "✅ Processed file: total_energy_drilling_activity_measurements.csv\n",
      "✅ Processed file: total_energy_electricity_end_use_and_electric_vehicle_use.csv\n",
      "✅ Processed file: total_energy_electricity_net_generation_commercial_and_industrial_sectors.csv\n",
      "✅ Processed file: total_energy_electricity_net_generation_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_electricity_net_generation_total_all_sectors.csv\n",
      "✅ Processed file: total_energy_electric_and_fuel_cell_electric_light-duty_vehicles_overview.csv\n",
      "✅ Processed file: total_energy_electric_net_summer_capacity_commercial_sector.csv\n",
      "✅ Processed file: total_energy_electric_net_summer_capacity_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_electric_net_summer_capacity_industrial_sector.csv\n",
      "✅ Processed file: total_energy_electric_net_summer_capacity_total_all_sectors.csv\n",
      "✅ Processed file: total_energy_electric_power_sector_energy_consumption.csv\n",
      "✅ Processed file: total_energy_electric_vehicle_charging_infrastructure.csv\n",
      "✅ Processed file: total_energy_energy_consumption_residential_commercial_and_industrial_sectors.csv\n",
      "✅ Processed file: total_energy_energy_consumption_transportation_sector_total_end-use_sectors_and_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_exports_by_country.csv\n",
      "✅ Processed file: total_energy_exports_by_country_of_destination.csv\n",
      "✅ Processed file: total_energy_exports_by_type.csv\n",
      "✅ Processed file: total_energy_fob_costs_of_crude_oil_imports_from_selected_countries.csv\n",
      "✅ Processed file: total_energy_fuel_ethanol_overview.csv\n",
      "✅ Processed file: total_energy_heating_degree-days_by_census_division.csv\n",
      "✅ Processed file: total_energy_heat_content_of_non-combustion_use_of_fossil_fuels.csv\n",
      "✅ Processed file: total_energy_heat_content_of_petroleum_products_supplied_by_type.csv\n",
      "✅ Processed file: total_energy_imports_and_exports_by_type.csv\n",
      "✅ Processed file: total_energy_imports_by_country.csv\n",
      "✅ Processed file: total_energy_imports_from_non-opec_countries.csv\n",
      "✅ Processed file: total_energy_imports_from_opec_countries.csv\n",
      "✅ Processed file: total_energy_industrial_sector.csv\n",
      "✅ Processed file: total_energy_industrial_sector_energy_consumption.csv\n",
      "✅ Processed file: total_energy_l2_charging_ports_per_location.csv\n",
      "✅ Processed file: total_energy_landed_costs_of_crude_oil_imports_from_selected_countries.csv\n",
      "✅ Processed file: total_energy_legacy_charging_ports.csv\n",
      "✅ Processed file: total_energy_level_1_charging_ports.csv\n",
      "✅ Processed file: total_energy_level_2_charging_ports.csv\n",
      "✅ Processed file: total_energy_light-duty_vehicle_average_miles_traveled_by_technology_type.csv\n",
      "✅ Processed file: total_energy_merchandise_trade_value.csv\n",
      "✅ Processed file: total_energy_motor_vehicle_mileage_fuel_consumption_and_fuel_economy.csv\n",
      "✅ Processed file: total_energy_natural_gas.csv\n",
      "✅ Processed file: total_energy_natural_gas_prices.csv\n",
      "✅ Processed file: total_energy_networked_ports_only.csv\n",
      "✅ Processed file: total_energy_networked__non-networked_port.csv\n",
      "✅ Processed file: total_energy_non-combustion_use_of_fossil_fuels_in_physical_units.csv\n",
      "✅ Processed file: total_energy_non-networked_ports_only.csv\n",
      "✅ Processed file: total_energy_nuclear_energy_overview.csv\n",
      "✅ Processed file: total_energy_other_biofuels_overview.csv\n",
      "✅ Processed file: total_energy_overview.csv\n",
      "✅ Processed file: total_energy_petroleum_consumption_and_fuel_ethanol.csv\n",
      "✅ Processed file: total_energy_petroleum_production_imports_and_exports.csv\n",
      "✅ Processed file: total_energy_population_us_gross_domestic_product_and_us_gross_output.csv\n",
      "✅ Processed file: total_energy_primary_energy_consumption_by_source.csv\n",
      "✅ Processed file: total_energy_primary_energy_consumption_by_source_fossil_fuel_equivalency_approach.csv\n",
      "✅ Processed file: total_energy_primary_energy_consumption_energy_expenditures_and_carbon_dioxide_emissions_indicators.csv\n",
      "✅ Processed file: total_energy_primary_energy_exports.csv\n",
      "✅ Processed file: total_energy_primary_energy_imports_by_source.csv\n",
      "✅ Processed file: total_energy_primary_energy_net_imports_by_source.csv\n",
      "✅ Processed file: total_energy_primary_energy_overview.csv\n",
      "✅ Processed file: total_energy_primary_energy_overview_fossil_fuel_equivalency_approach.csv\n",
      "✅ Processed file: total_energy_primary_energy_production_by_source.csv\n",
      "✅ Processed file: total_energy_primary_energy_production_by_source_fossil_fuel_equivalency_approach.csv\n",
      "✅ Processed file: total_energy_private_ports_only.csv\n",
      "✅ Processed file: total_energy_production_and_consumption_by_source.csv\n",
      "✅ Processed file: total_energy_products_supplied_by_type.csv\n",
      "✅ Processed file: total_energy_public_ports_only.csv\n",
      "✅ Processed file: total_energy_public__private_ports.csv\n",
      "✅ Processed file: total_energy_refinery_and_blender_net_inputs_and_net_production.csv\n",
      "✅ Processed file: total_energy_refiner_prices_of_petroleum_products_for_resale.csv\n",
      "✅ Processed file: total_energy_refiner_prices_of_petroleum_products_to_end_users.csv\n",
      "✅ Processed file: total_energy_refiner_prices_of_residual_fuel_oil.csv\n",
      "✅ Processed file: total_energy_renewable_diesel_fuel_overview.csv\n",
      "✅ Processed file: total_energy_renewable_energy_production_and_consumption_by_source_fossil_fuel_equivalency_approach.csv\n",
      "✅ Processed file: total_energy_residential_and_commercial_sectors.csv\n",
      "✅ Processed file: total_energy_residential_sector_energy_consumption.csv\n",
      "✅ Processed file: total_energy_retail_motor_gasoline_and_on-highway_diesel_fuel_prices.csv\n",
      "✅ Processed file: total_energy_solar_electricity_net_generation.csv\n",
      "✅ Processed file: total_energy_solar_energy_consumption.csv\n",
      "✅ Processed file: total_energy_stocks.csv\n",
      "✅ Processed file: total_energy_stocks_by_sector.csv\n",
      "✅ Processed file: total_energy_stocks_of_coal_and_petroleum_electric_power_sector.csv\n",
      "✅ Processed file: total_energy_total_locations.csv\n",
      "✅ Processed file: total_energy_total_ports.csv\n",
      "✅ Processed file: total_energy_trade_overview.csv\n",
      "✅ Processed file: total_energy_transportation_and_electric_power_sectors.csv\n",
      "✅ Processed file: total_energy_transportation_sector_energy_consumption.csv\n",
      "✅ Processed file: total_energy_underground_storage.csv\n",
      "✅ Processed file: total_energy_uranium_overview.csv\n",
      "✅ Processed file: total_energy_wells_and_footage_drilled.csv\n",
      "✅ Processed file: total_energy__us_government_energy_consumption_by_agency_fiscal_years.csv\n",
      "✅ Processed file: total_energy__us_government_energy_consumption_by_source_fiscal_years.csv\n",
      "✅ Final Total Energy dataframe ready!\n",
      "✅ Merged SEDS and Total Energy it metadata dataframe\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Run all data loads\n",
    "# =========================\n",
    "\n",
    "atb_df = load_atb()\n",
    "recs_df = load_recs()\n",
    "rmi_df = load_rmi()\n",
    "\n",
    "seds_df = load_seds()\n",
    "total_df = load_total_energy()\n",
    "seds_and_total_df = merge_seds_and_total(seds_df, total_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe57698e-1435-40bf-9557-fc1633f48e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final combined dataset shape: (595242, 3)\n"
     ]
    }
   ],
   "source": [
    "final_energy_df = final_concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab218b2e-4abb-4e59-b026-838eb35e2320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>US</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>US</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951</td>\n",
       "      <td>US</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1952</td>\n",
       "      <td>US</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953</td>\n",
       "      <td>US</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595237</th>\n",
       "      <td>2025</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595238</th>\n",
       "      <td>2025</td>\n",
       "      <td>Washington</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595239</th>\n",
       "      <td>2025</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595240</th>\n",
       "      <td>2025</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595241</th>\n",
       "      <td>2025</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>{'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595242 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year          state                                           metadata\n",
       "0       1949             US  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...\n",
       "1       1950             US  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...\n",
       "2       1951             US  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...\n",
       "3       1952             US  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...\n",
       "4       1953             US  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_appro...\n",
       "...      ...            ...                                                ...\n",
       "595237  2025       Virginia  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...\n",
       "595238  2025     Washington  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...\n",
       "595239  2025  West Virginia  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...\n",
       "595240  2025      Wisconsin  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...\n",
       "595241  2025        Wyoming  {'SEDS_AND_TOTAL_ENERGY': {'total_energy_dcfc_...\n",
       "\n",
       "[595242 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_energy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "933aa924-84f6-435e-9b19-ca44e8728d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved final_energy_df to STAT 390 Project/Energy Data/final_energy_df.csv\n"
     ]
    }
   ],
   "source": [
    "# 📂 Save the final_energy_df to a CSV file\n",
    "final_csv_path = 'STAT 390 Project/Energy Data/final_energy_df.csv'\n",
    "\n",
    "# Save to CSV\n",
    "final_energy_df.to_csv('STAT 390 Project/Energy Data/final_energy_df.csv')\n",
    "\n",
    "print(f\"✅ Saved final_energy_df to {final_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
